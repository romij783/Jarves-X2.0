<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no">
    <title>JARVIS X | VIVO Y17 CORE</title>
    <link href="https://fonts.googleapis.com/css2?family=Orbitron:wght@400;700&family=Share+Tech+Mono&display=swap" rel="stylesheet">
    <style>
        :root { --neon: #00f2ff; --glow: rgba(0, 242, 255, 0.3); --warn: #ff004c; --bg: #000; }
        * { margin:0; padding:0; box-sizing:border-box; -webkit-tap-highlight-color:transparent; }
        body { background: var(--bg); color: var(--neon); font-family: 'Share Tech Mono', monospace; height: 100vh; overflow:hidden; }

        /* HUD BACKGROUND */
        #vision-bg { position: fixed; top: 0; left: 0; width: 100%; height: 100%; object-fit: cover; z-index: -2; opacity: 0; transition: 0.5s; filter: brightness(0.5) contrast(1.2); }
        .cam-active #vision-bg { opacity: 0.6; }
        #capture-canvas { display: none; }

        .hud-overlay { position: fixed; inset: 0; background: radial-gradient(circle, transparent 30%, rgba(0,0,0,0.8) 100%); z-index: -1; pointer-events: none; }
        .grid-lines { position: fixed; inset: 0; background: linear-gradient(var(--glow) 1px, transparent 1px) 0 0 / 50px 50px, linear-gradient(90deg, var(--glow) 1px, transparent 1px) 0 0 / 50px 50px; z-index: -1; opacity: 0.05; }

        .header { position: absolute; top: 0; width: 100%; padding: 15px; display: flex; justify-content: space-between; font-size: 10px; border-bottom: 1px solid var(--glow); background: rgba(0,0,0,0.6); z-index: 10; }
        
        /* CENTRAL INTERFACE */
        .main-core { height: 100vh; display: flex; flex-direction: column; align-items: center; justify-content: center; position: relative; }
        .arc-reactor { position: relative; width: 180px; height: 180px; display: flex; align-items: center; justify-content: center; }
        .ring { position: absolute; border-radius: 50%; border: 2px solid var(--neon); box-shadow: 0 0 15px var(--glow); }
        .ring-1 { width: 100%; height: 100%; border-style: dashed; animation: rotate 12s linear infinite; }
        .ring-2 { width: 80%; height: 80%; border-style: double; animation: rotate 8s linear reverse infinite; opacity: 0.6; }
        .core { width: 50px; height: 50px; background: var(--neon); border-radius: 50%; box-shadow: 0 0 40px var(--neon); transition: 0.3s; }

        .listening .core { background: var(--warn); box-shadow: 0 0 60px var(--warn); transform: scale(0.8); }
        .speaking .core { animation: speak-pulse 0.4s infinite alternate; }

        /* DATA TERMINAL */
        .terminal { position: absolute; bottom: 140px; width: 90%; height: 90px; background: rgba(0,0,0,0.6); border-left: 3px solid var(--neon); padding: 10px; font-size: 11px; overflow-y: auto; backdrop-filter: blur(5px); }

        /* AUTH PANEL */
        .auth-panel { position: absolute; bottom: 0; width: 100%; padding: 20px; background: rgba(0,0,0,0.9); display: flex; flex-direction: column; gap: 10px; z-index: 20; border-top: 1px solid var(--neon); }
        .api-row { display: flex; gap: 10px; }
        input { flex: 1; background: #111; border: 1px solid var(--neon); color: var(--neon); padding: 12px; font-size: 12px; outline: none; }
        .check-btn { background: var(--neon); color: #000; border: none; padding: 0 20px; font-family: 'Orbitron'; font-weight: bold; font-size: 11px; cursor: pointer; text-transform: uppercase; }

        @keyframes rotate { from { transform: rotate(0deg); } to { transform: rotate(360deg); } }
        @keyframes speak-pulse { from { transform: scale(1); box-shadow: 0 0 30px var(--neon); } to { transform: scale(1.3); box-shadow: 0 0 60px var(--neon); } }
    </style>
</head>
<body>

    <video id="vision-bg" autoplay playsinline></video>
    <canvas id="capture-canvas"></canvas>
    <div class="hud-overlay"></div>
    <div class="grid-lines"></div>

    <div class="header">
        <div>CORE: JARVIS X // VIVO Y17</div>
        <div id="batt">PWR: --</div>
    </div>

    <div class="main-core" id="ui">
        <div class="arc-reactor">
            <div class="ring ring-1"></div>
            <div class="ring ring-2"></div>
            <div class="core"></div>
        </div>

        <div class="terminal" id="logs">
            <div style="color: var(--neon)">>> STANDING BY. ENTER KEY & CHECK-IN.</div>
        </div>
    </div>

    <div class="auth-panel">
        <div class="api-row">
            <input type="password" id="api-key" placeholder="ACCESS TOKEN">
            <button class="check-btn" id="check-in">CHECK-IN</button>
        </div>
        <div style="font-size: 9px; text-align: center; opacity: 0.6; letter-spacing: 2px;">NEURAL UPLINK STANDBY</div>
    </div>

    <script>
        const logs = document.getElementById('logs');
        const ui = document.getElementById('ui');
        const video = document.getElementById('vision-bg');
        const canvas = document.getElementById('capture-canvas');
        const apiKeyInput = document.getElementById('api-key');
        const checkBtn = document.getElementById('check-in');

        let isInitialized = false;
        let isSpeaking = false;
        let isCamActive = false;
        let recognition;
        const synth = window.speechSynthesis;

        if(localStorage.getItem('jx_final_key')) apiKeyInput.value = localStorage.getItem('jx_final_key');

        // --- 1. HUMAN VOICE ENGINE ---
        function speak(text) {
            synth.cancel();
            setTimeout(() => {
                const utterance = new SpeechSynthesisUtterance(text);
                const voices = synth.getVoices();
                utterance.voice = voices.find(v => (v.lang.includes('bn') || v.lang.includes('en-IN')) && v.name.includes('Male')) || voices[0];
                utterance.pitch = 0.95; 
                utterance.rate = 1.0; 

                utterance.onstart = () => { ui.classList.add('speaking'); isSpeaking = true; };
                utterance.onend = () => { 
                    ui.classList.remove('speaking'); 
                    isSpeaking = false; 
                    if(isInitialized) restartRec(); 
                };
                synth.speak(utterance);
            }, 400);
        }

        // --- 2. ADVANCED CAMERA CONTROL (FIXED) ---
        async function controlCamera(action) {
            if(action === 'on') {
                try {
                    const stream = await navigator.mediaDevices.getUserMedia({ video: { facingMode: "environment" } });
                    video.srcObject = stream;
                    document.body.classList.add('cam-active');
                    isCamActive = true;
                    return "Optical sensors online, sir.";
                } catch(e) { return "Unable to link optical sensors."; }
            } else {
                if(video.srcObject) {
                    video.srcObject.getTracks().forEach(track => track.stop());
                    video.srcObject = null;
                }
                document.body.classList.remove('cam-active');
                isCamActive = false;
                return "Vision systems deactivated.";
            }
        }

        async function analyzeVision(prompt) {
            if(!isCamActive) return "Sir, please enable vision first.";
            addLog('JARVIS', 'SCANNING VISUAL DATA...');
            canvas.width = video.videoWidth;
            canvas.height = video.videoHeight;
            canvas.getContext('2d').drawImage(video, 0, 0);
            const base64 = canvas.toDataURL('image/jpeg', 0.5).split(',')[1];

            try {
                const res = await fetch("https://openrouter.ai/api/v1/chat/completions", {
                    method: "POST",
                    headers: { "Authorization": `Bearer ${apiKeyInput.value}`, "Content-Type": "application/json" },
                    body: JSON.stringify({
                        "model": "google/gemini-pro-1.5-exp",
                        "messages": [{ "role": "user", "content": [
                            { "type": "text", "text": `Reply to: ${prompt}. Look at the image and reply in the same language (Bangla/English/Banglish). Be sharp like Jarvis.` },
                            { "type": "image_url", "image_url": { "url": `data:image/jpeg;base64,${base64}` } }
                        ]}]
                    })
                });
                const data = await res.json();
                return data.choices[0].message.content;
            } catch(e) { return "Vision uplink failed."; }
        }

        // --- 3. NEURAL PROCESSOR ---
        async function handleAI(input) {
            const low = input.toLowerCase();
            addLog('USER', input);

            // Command: Camera ON
            if(low.includes('camera on') || low.includes('vision on') || low.includes('ক্যামেরা অন')) {
                const res = await controlCamera('on');
                addLog('JARVIS', res); speak(res); return;
            }

            // Command: Camera OFF
            if(low.includes('camera off') || low.includes('vision off') || low.includes('ক্যামেরা বন্ধ')) {
                const res = await controlCamera('off');
                addLog('JARVIS', res); speak(res); return;
            }

            // Command: System
            if(low.includes('vibrate')) { navigator.vibrate(300); speak("Haptics engaged."); return; }
            if(low.includes('battery')) { speak(`Power level is ${document.getElementById('batt').textContent}.`); return; }

            // Command: Vision Intelligence
            if(isCamActive && (low.includes('look') || low.includes('see') || low.includes('কি') || low.includes('দেখছ'))) {
                const vis = await analyzeVision(input);
                addLog('JARVIS', vis); speak(vis); return;
            }

            // Chat Logic
            try {
                const res = await fetch("https://openrouter.ai/api/v1/chat/completions", {
                    method: "POST",
                    headers: { "Authorization": `Bearer ${apiKeyInput.value}`, "Content-Type": "application/json" },
                    body: JSON.stringify({
                        "model": "openai/gpt-4o-mini",
                        "messages": [
                            { "role": "system", "content": "You are JARVIS X. Intelligent, calm. Multilingual (Bangla, English, Banglish). Always reply in the user's language. Keep it brief." },
                            { "role": "user", "content": input }
                        ]
                    })
                });
                const data = await res.json();
                const reply = data.choices[0].message.content;
                addLog('JARVIS', reply);
                speak(reply);
            } catch(e) { speak("Neural uplink interrupted."); }
        }

        // --- 4. RECOGNITION ENGINE ---
        if('webkitSpeechRecognition' in window) {
            recognition = new webkitSpeechRecognition();
            recognition.continuous = false;
            recognition.onstart = () => ui.classList.add('listening');
            recognition.onend = () => { ui.classList.remove('listening'); if(isInitialized && !isSpeaking) restartRec(); };
            recognition.onresult = (e) => handleAI(e.results[0][0].transcript);
        }
        function restartRec() { try { recognition.start(); } catch(e){} }

        // --- 5. INITIALIZE ---
        checkBtn.onclick = () => {
            const key = apiKeyInput.value.trim();
            if(!key) { alert("API KEY REQUIRED"); return; }
            localStorage.setItem('jx_final_key', key);
            isInitialized = true;
            
            speak("System check-in complete. I am now linked to your Vivo device. All modules nominal.");
            addLog('SYS', 'JARVIS ONLINE');
            restartRec();
            
            checkBtn.textContent = "VERIFIED";
            checkBtn.style.background = "#0f0";
        };

        function addLog(who, msg) {
            const d = document.createElement('div');
            d.innerHTML = `<span style="color:var(--neon)">> ${who}:</span> ${msg.toUpperCase()}`;
            logs.appendChild(d);
            logs.scrollTop = logs.scrollHeight;
        }

        navigator.getBattery().then(b => {
            const up = () => document.getElementById('batt').textContent = `PWR: ${Math.round(b.level*100)}%`;
            b.onlevelchange = up; up();
        });
        window.speechSynthesis.onvoiceschanged = () => synth.getVoices();
    </script>
</body>
</html>
